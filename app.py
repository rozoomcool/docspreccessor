import json
import uuid
from typing import Any, Dict, List, Optional, Tuple

import streamlit as st
import pandas as pd
import pdfplumber
from docx import Document
import ollama


MODEL_NAME = "qwen3:8b"


# ===============================
# Session State Initialization
# ===============================

def init_session_state() -> None:
    """Initialize all required keys in session_state."""
    if "schema_fields" not in st.session_state:
        # Each field: {"name": str, "type": "string"/"number"/"boolean", "required": bool, "description": str}
        st.session_state.schema_fields: List[Dict[str, Any]] = []

    if "templates" not in st.session_state:
        # name -> schema dict
        st.session_state.templates: Dict[str, Dict[str, Any]] = {}

    if "processed_docs" not in st.session_state:
        # List of dicts with metadata, raw text, json_result, dataframe
        st.session_state.processed_docs: List[Dict[str, Any]] = []

    if "selected_doc_id" not in st.session_state:
        st.session_state.selected_doc_id: Optional[str] = None

    if "show_result_modal" not in st.session_state:
        st.session_state.show_result_modal: bool = False


# ===============================
# JSON Schema Builder Logic
# ===============================

def build_json_schema(fields: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Generate JSON schema of fixed shape from field definitions."""
    properties: Dict[str, Dict[str, Any]] = {}
    required: List[str] = []

    for field in fields:
        name = field.get("name", "").strip()
        field_type = field.get("type", "string")
        is_required = bool(field.get("required", False))

        if not name:
            # Ignore empty names in final schema
            continue

        properties[name] = {"type": field_type}
        if is_required:
            required.append(name)

    schema: Dict[str, Any] = {
        "type": "array",
        "items": {
            "type": "object",
            "properties": properties,
            "required": required,
        },
    }
    return schema


def validate_schema_fields(fields: List[Dict[str, Any]]) -> Tuple[bool, Optional[str]]:
    """Basic validation for fields before saving template."""
    names = [f.get("name", "").strip() for f in fields if f.get("name", "").strip()]
    if not names:
        return False, "Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ñ…Ð¾Ñ‚Ñ Ð±Ñ‹ Ð¾Ð´Ð½Ð¾ Ð¿Ð¾Ð»Ðµ Ñ Ð½ÐµÐ¿ÑƒÑÑ‚Ñ‹Ð¼ Ð¸Ð¼ÐµÐ½ÐµÐ¼."

    if len(set(names)) != len(names):
        return False, "Ð˜Ð¼ÐµÐ½Ð° Ð¿Ð¾Ð»ÐµÐ¹ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸."

    return True, None


def render_schema_builder() -> None:
    """Render UI for JSON schema builder."""
    st.subheader("Structured Output Builder")

    st.markdown("**Ð‘Ð°Ð·Ð¾Ð²Ð°Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°:** `array` Ð¸Ð· `object` Ð±ÐµÐ· Ð²Ð»Ð¾Ð¶ÐµÐ½Ð½Ñ‹Ñ… Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð².")

    add_col, _ = st.columns([1, 4])
    if add_col.button("âž• Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»Ðµ", key="add_field"):
        st.session_state.schema_fields.append(
            {
                "name": f"field_{len(st.session_state.schema_fields) + 1}",
                "type": "string",
                "required": False,
                "description": "",
            }
        )

    # Render fields
    for idx, field in enumerate(st.session_state.schema_fields):
        with st.container():
            # Backward compatibility for existing session_state without descriptions
            if "description" not in field:
                field["description"] = ""

            cols = st.columns([3, 2, 1, 1])
            field_name = cols[0].text_input(
                "Ð˜Ð¼Ñ Ð¿Ð¾Ð»Ñ",
                value=field["name"],
                key=f"field_name_{idx}",
            )
            field_type = cols[1].selectbox(
                "Ð¢Ð¸Ð¿",
                options=["string", "number", "boolean"],
                index=["string", "number", "boolean"].index(field["type"]),
                key=f"field_type_{idx}",
            )
            is_required = cols[2].checkbox(
                "required",
                value=field["required"],
                key=f"field_required_{idx}",
            )
            remove = cols[3].button("ðŸ—‘ï¸", key=f"remove_field_{idx}")

            field_description = st.text_area(
                "ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ (Ð¿Ð¾Ð´ÑÐºÐ°Ð·ÐºÐ° Ð´Ð»Ñ LLM, ÐºÐ¾Ð³Ð´Ð° Ð¿Ð¾ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÑŽ Ð½ÐµÐ¿Ð¾Ð½ÑÑ‚Ð½Ð¾)",
                value=field.get("description", ""),
                key=f"field_description_{idx}",
                height=68,
                placeholder="ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Â«Ð¡ÑƒÐ¼Ð¼Ð° Ðº Ð¾Ð¿Ð»Ð°Ñ‚Ðµ Ð² Ñ€ÑƒÐ±Ð»ÑÑ…Â», Â«Ð”Ð°Ñ‚Ð° ÑÑ‡ÐµÑ‚Ð° Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ YYYY-MM-DDÂ», Â«Ð˜ÐÐ Ð¿Ð¾ÑÑ‚Ð°Ð²Ñ‰Ð¸ÐºÐ°Â»",
            )

            # Update state
            field["name"] = field_name
            field["type"] = field_type
            field["required"] = is_required
            field["description"] = field_description

            if remove:
                st.session_state.schema_fields.pop(idx)
                st.experimental_rerun()

    schema = build_json_schema(st.session_state.schema_fields)

    st.markdown("**Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ JSON-ÑÑ…ÐµÐ¼Ð°:**")
    st.json(schema)

    st.markdown("---")
    st.subheader("Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ ÑˆÐ°Ð±Ð»Ð¾Ð½")

    template_name = st.text_input("Ð˜Ð¼Ñ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°", key="template_name_input")
    if st.button("ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ ÑˆÐ°Ð±Ð»Ð¾Ð½"):
        is_valid, error = validate_schema_fields(st.session_state.schema_fields)
        if not is_valid:
            st.error(error)
            return

        name = template_name.strip()
        if not name:
            st.error("Ð˜Ð¼Ñ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð° Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¿ÑƒÑÑ‚Ñ‹Ð¼.")
            return

        if name in st.session_state.templates:
            st.error("Ð¨Ð°Ð±Ð»Ð¾Ð½ Ñ Ñ‚Ð°ÐºÐ¸Ð¼ Ð¸Ð¼ÐµÐ½ÐµÐ¼ ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³Ð¾Ðµ Ð¸Ð¼Ñ.")
            return

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¸ "Ñ‡Ð¸ÑÑ‚ÑƒÑŽ" JSON-ÑÑ…ÐµÐ¼Ñƒ, Ð¸ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾Ð»ÐµÐ¹ (Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ),
        # Ð½Ð¾ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ ÐÐ• Ð¿Ð¾Ð¿Ð°Ð´Ð°ÑŽÑ‚ Ð² schema, Ð° Ð¸Ð´ÑƒÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² prompt.
        fields_meta = [
            {
                "name": f.get("name", "").strip(),
                "type": f.get("type", "string"),
                "required": bool(f.get("required", False)),
                "description": (f.get("description") or "").strip(),
            }
            for f in st.session_state.schema_fields
            if f.get("name", "").strip()
        ]

        st.session_state.templates[name] = {
            "schema": schema,
            "fields": fields_meta,
        }
        st.success(f"Ð¨Ð°Ð±Ð»Ð¾Ð½ Â«{name}Â» ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½.")


# ===============================
# Document Text Extraction
# ===============================

def extract_text_from_file(uploaded_file) -> str:
    """Detect file type by extension / MIME and extract text."""
    filename = uploaded_file.name.lower()

    if filename.endswith(".pdf"):
        return extract_text_from_pdf(uploaded_file)
    elif filename.endswith(".docx"):
        return extract_text_from_docx(uploaded_file)
    elif filename.endswith(".txt"):
        return extract_text_from_txt(uploaded_file)
    elif filename.endswith(".csv"):
        return extract_text_from_tabular(uploaded_file, file_type="csv")
    elif filename.endswith((".xls", ".xlsx")):
        return extract_text_from_tabular(uploaded_file, file_type="excel")
    else:
        raise ValueError("ÐÐµÐ¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ„Ð°Ð¹Ð»Ð°.")


def extract_text_from_pdf(uploaded_file) -> str:
    with pdfplumber.open(uploaded_file) as pdf:
        pages_text = [page.extract_text() or "" for page in pdf.pages]
    return "\n\n".join(pages_text).strip()


def extract_text_from_docx(uploaded_file) -> str:
    # python-docx expects a file-like object
    doc = Document(uploaded_file)
    paragraphs = [p.text for p in doc.paragraphs]
    return "\n".join(paragraphs).strip()


def extract_text_from_txt(uploaded_file) -> str:
    content = uploaded_file.read()
    try:
        return content.decode("utf-8")
    except UnicodeDecodeError:
        return content.decode("latin-1", errors="ignore")


def extract_text_from_tabular(uploaded_file, file_type: str) -> str:
    if file_type == "csv":
        df = pd.read_csv(uploaded_file)
    elif file_type == "excel":
        df = pd.read_excel(uploaded_file, engine="openpyxl")
    else:
        raise ValueError("ÐÐµÐ¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ð¹ Ñ‚Ð¸Ð¿ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹.")

    # Represent table as readable text
    return df.to_string(index=False)


# ===============================
# JSON Validation Against Schema
# ===============================

def validate_against_schema(data: Any, schema: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
    """
    Minimal JSON validation:
    - top-level array
    - each item is object
    - required fields present
    - no unexpected types (very basic check)
    """
    if not isinstance(data, list):
        return False, "ÐžÐ¶Ð¸Ð´Ð°ÐµÑ‚ÑÑ Ð¼Ð°ÑÑÐ¸Ð² (`type: array`) Ð½Ð° Ð²ÐµÑ€Ñ…Ð½ÐµÐ¼ ÑƒÑ€Ð¾Ð²Ð½Ðµ."

    item_schema = schema.get("items", {})
    properties = item_schema.get("properties", {})
    required_fields = item_schema.get("required", [])

    for idx, item in enumerate(data):
        if not isinstance(item, dict):
            return False, f"Ð­Ð»ÐµÐ¼ÐµÐ½Ñ‚ Ñ Ð¸Ð½Ð´ÐµÐºÑÐ¾Ð¼ {idx} Ð½Ðµ ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð¼."

        # Required fields
        for req in required_fields:
            if req not in item or item[req] in (None, ""):
                return False, f"Ð­Ð»ÐµÐ¼ÐµÐ½Ñ‚ {idx}: Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¸Ð»Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ðµ required-Ð¿Ð¾Ð»Ðµ '{req}'."

        # Optional: basic type checks
        for key, value in item.items():
            if key not in properties:
                # Ð”Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ð»Ñ, Ð½Ð¾ Ð¼Ð¾Ð¶Ð½Ð¾ Ð·Ð°Ð¿Ñ€ÐµÑ‚Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¸ Ð¶ÐµÐ»Ð°Ð½Ð¸Ð¸
                continue

            expected_type = properties[key].get("type")
            if expected_type == "string" and not isinstance(value, str):
                return False, f"ÐŸÐ¾Ð»Ðµ '{key}' Ð² ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ðµ {idx} Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ ÑÑ‚Ñ€Ð¾ÐºÐ¾Ð¹."
            elif expected_type == "number" and not isinstance(value, (int, float)):
                return False, f"ÐŸÐ¾Ð»Ðµ '{key}' Ð² ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ðµ {idx} Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ñ‡Ð¸ÑÐ»Ð¾Ð¼."
            elif expected_type == "boolean" and not isinstance(value, bool):
                return False, f"ÐŸÐ¾Ð»Ðµ '{key}' Ð² ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ðµ {idx} Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð±ÑƒÐ»ÐµÐ²Ñ‹Ð¼."

    return True, None


# ===============================
# LLM Interaction (Ollama) â€“ Structured Extraction
# ===============================

def build_extraction_prompt(
    schema: Dict[str, Any],
    text: str,
    fields_meta: Optional[List[Dict[str, Any]]] = None,
) -> str:
    """
    Build a deterministic prompt for structured extraction.
    Focus: Document â†’ Text â†’ JSON Array (matching schema).
    """
    schema_str = json.dumps(schema, ensure_ascii=False, indent=2)

    # Optional field hints: Ð±ÐµÑ€Ñ‘Ð¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð· Ð¿Ð¾Ð»ÐµÐ¹-ÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ‚Ð¾Ñ€Ð°,
    # Ð½Ðµ Ð²ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°Ñ Ð¸Ñ… Ð² ÑÐ°Ð¼Ñƒ JSON-ÑÑ…ÐµÐ¼Ñƒ.
    hints_lines: List[str] = []
    if fields_meta:
        for f in fields_meta:
            name = (f.get("name") or "").strip()
            desc = (f.get("description") or "").strip()
            if not name or not desc:
                continue
            ftype = f.get("type", "string")
            hints_lines.append(f"- {name} ({ftype}): {desc}")

    hints_block = ""
    if hints_lines:
        hints_block = "\n\nÐžÐŸÐ˜Ð¡ÐÐÐ˜Ð¯ ÐŸÐžÐ›Ð•Ð™ (ÐºÐ°Ðº Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ñ‚ÑŒ/Ñ‡Ñ‚Ð¾ Ð¸Ð·Ð²Ð»ÐµÐºÐ°Ñ‚ÑŒ):\n" + "\n".join(hints_lines)

    prompt = f"""
Ð¢Ñ‹ â€“ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°.

Ð¢Ð’ÐžÐ¯ Ð—ÐÐ”ÐÐ§Ð:
1. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°.
2. Ð˜Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ JSON, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¹ JSON-ÑÑ…ÐµÐ¼Ðµ.
3. Ð’ÐµÑ€Ð½ÑƒÑ‚ÑŒ Ð¢ÐžÐ›Ð¬ÐšÐž Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¹ JSON Ð±ÐµÐ· ÐºÐ°ÐºÐ¸Ñ…-Ð»Ð¸Ð±Ð¾ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹, ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² Ð¸Ð»Ð¸ Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð¾/Ð¿Ð¾ÑÐ»Ðµ.

JSON-ÑÑ…ÐµÐ¼Ð° (Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°):

{schema_str}
{hints_block}

Ð¢Ð Ð•Ð‘ÐžÐ’ÐÐÐ˜Ð¯:
- Ð’ÐµÑ€Ñ…Ð½Ð¸Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°: Ð²ÑÐµÐ³Ð´Ð° JSON-Ð¼Ð°ÑÑÐ¸Ð² (`type: "array"`).
- ÐšÐ°Ð¶Ð´Ñ‹Ð¹ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚ Ð¼Ð°ÑÑÐ¸Ð²Ð° â€“ Ð¾Ð±ÑŠÐµÐºÑ‚ (`type: "object"`).
- ÐŸÐ¾Ð»Ñ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¾Ð²Ð°Ñ‚ÑŒ `properties` Ð¸ `required` Ð¸Ð· ÑÑ…ÐµÐ¼Ñ‹.
- Ð•ÑÐ»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‚, Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¼Ð°ÑÑÐ¸Ð²: [].
- ÐÐ• Ð”ÐžÐ‘ÐÐ’Ð›Ð¯Ð™ Ð¿Ð¾Ð»ÐµÐ¹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… Ð½ÐµÑ‚ Ð² ÑÑ…ÐµÐ¼Ðµ.
- ÐÐ• ÐŸÐ˜Ð¨Ð˜ ÐÐ˜ÐšÐÐšÐžÐ“Ðž Ð¢Ð•ÐšÐ¡Ð¢Ð, ÐšÐ ÐžÐœÐ• JSON.

Ð¢Ð•ÐšÐ¡Ð¢ Ð”ÐžÐšÐ£ÐœÐ•ÐÐ¢Ð Ð”Ð›Ð¯ ÐÐÐÐ›Ð˜Ð—Ð:

{text}
""".strip()

    return prompt


def call_ollama(prompt: str, model: str = MODEL_NAME, temperature: float = 0.0) -> str:
    """
    Call Ollama locally using the python client.
    Returns raw string content from the model.
    """
    response = ollama.chat(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        options={"temperature": temperature},
        # format="json"  # ÐœÐ¾Ð¶Ð½Ð¾ Ð²ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ ÑÑ‚Ñ€Ð¾Ð³Ð¾Ð³Ð¾ JSON-Ð²Ñ‹Ð²Ð¾Ð´Ð°, ÐµÑÐ»Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚
    )
    # For chat API, response structure: {"message": {"role": "...", "content": "..."}}
    return response["message"]["content"]


def extract_structured_data(
    schema: Dict[str, Any],
    text: str,
    fields_meta: Optional[List[Dict[str, Any]]] = None,
    max_retries: int = 1,
) -> Tuple[Optional[Any], str, Optional[str]]:
    """
    Call LLM to extract structured data.
    - Returns (parsed_json_or_None, raw_output, validation_error_or_None).
    - Performs up to (max_retries + 1) attempts if JSON invalid or schema validation fails.
    """
    base_prompt = build_extraction_prompt(schema, text, fields_meta=fields_meta)
    last_raw_output: str = ""
    last_error: Optional[str] = None

    for attempt in range(max_retries + 1):
        if attempt == 0:
            prompt = base_prompt
        else:
            # On retry, reinforce JSON-only requirement
            prompt = base_prompt + """

Ð’ÐÐ–ÐÐž:
ÐŸÑ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð±Ñ‹Ð» Ð½ÐµÐ²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¼ JSON.
Ð¡ÐµÐ¹Ñ‡Ð°Ñ Ð²ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¹ JSON, ÑÑ‚Ñ€Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ ÑÑ…ÐµÐ¼Ðµ.
ÐÐµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð½Ð¸ÐºÐ°ÐºÐ¸Ñ… ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² Ð¸Ð»Ð¸ Ñ‚ÐµÐºÑÑ‚Ð° Ð²Ð½Ðµ JSON.
""".strip()

        raw_output = call_ollama(prompt)
        last_raw_output = raw_output

        try:
            parsed = json.loads(raw_output)
        except json.JSONDecodeError as e:
            last_error = f"ÐžÑˆÐ¸Ð±ÐºÐ° JSONDecode: {e}"
            continue

        is_valid, error = validate_against_schema(parsed, schema)
        if is_valid:
            return parsed, raw_output, None

        last_error = error

    # If we are here, all attempts failed
    return None, last_raw_output, last_error


# ===============================
# LLM Interaction (Ollama) â€“ Document Analysis / Summarization
# ===============================

def build_summary_prompt(
    text: str,
    focus: Optional[str] = None,
    level: str = "balanced",
) -> str:
    """
    Build prompt for non-structured document analysis / summarization.
    level: "short" | "balanced" | "detailed"
    """
    if level == "short":
        length_req = "Ð¡Ð´ÐµÐ»Ð°Ð¹ Ð¾Ñ‡ÐµÐ½ÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ (3â€“5 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹)."
    elif level == "detailed":
        length_req = "Ð¡Ð´ÐµÐ»Ð°Ð¹ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ñ‹Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¾Ð±Ð·Ð¾Ñ€ Ñ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ð¼Ð¸ Ð¿ÑƒÐ½ÐºÑ‚Ð°Ð¼Ð¸ Ð¸ Ð²Ñ‹Ð²Ð¾Ð´Ð°Ð¼Ð¸."
    else:
        length_req = "Ð¡Ð´ÐµÐ»Ð°Ð¹ ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ (5â€“10 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹) Ñ ÑÐ°Ð¼Ñ‹Ð¼Ð¸ Ð²Ð°Ð¶Ð½Ñ‹Ð¼Ð¸ Ñ„Ð°ÐºÑ‚Ð°Ð¼Ð¸."

    focus_text = ""
    if focus and focus.strip():
        focus_text = f"\nÐ”ÐžÐŸÐžÐ›ÐÐ˜Ð¢Ð•Ð›Ð¬ÐÐ«Ð™ Ð¤ÐžÐšÐ£Ð¡ ÐÐÐÐÐÐ›Ð˜Ð—Ð:\n{focus.strip()}\n"

    prompt = f"""
Ð¢Ñ‹ â€“ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð¿Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ñƒ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð².

Ð¢Ð’ÐžÐ¯ Ð—ÐÐ”ÐÐ§Ð:
1. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°.
2. Ð’Ñ‹Ð´ÐµÐ»Ð¸Ñ‚ÑŒ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼Ñ‹ÑÐ»Ð¸, Ñ„Ð°ÐºÑ‚Ñ‹, Ñ€Ð¸ÑÐºÐ¸ Ð¸ Ð²Ñ‹Ð²Ð¾Ð´Ñ‹.
3. Ð¡Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‡Ð¸Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.

Ð¢Ð Ð•Ð‘ÐžÐ’ÐÐÐ˜Ð¯ Ðš Ð¤ÐžÐ ÐœÐÐ¢Ð£:
- {length_req}
- ÐÐµ Ð¿Ð¸ÑˆÐ¸ Ð½Ð¸Ñ‡ÐµÐ³Ð¾, ÐºÑ€Ð¾Ð¼Ðµ ÑÐ°Ð¼Ð¾Ð³Ð¾ Ñ€ÐµÐ·ÑŽÐ¼Ðµ.
- Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¼Ð°Ñ€ÐºÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð»Ð¸ Ð½ÑƒÐ¼ÐµÑ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¿Ð¸ÑÐºÐ¸, ÐµÑÐ»Ð¸ ÑÑ‚Ð¾ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ Ð»ÑƒÑ‡ÑˆÐµ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚.{focus_text}
Ð¢Ð•ÐšÐ¡Ð¢ Ð”ÐžÐšÐ£ÐœÐ•ÐÐ¢Ð:

{text}
""".strip()

    return prompt


def summarize_document(
    text: str,
    focus: Optional[str] = None,
    level: str = "balanced",
) -> str:
    """High-level helper: build summary prompt and call Ollama."""
    prompt = build_summary_prompt(text, focus=focus, level=level)
    # Ð”Ð»Ñ ÑÑƒÐ¼Ð¼Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð´Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÑƒÑŽ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ
    return call_ollama(prompt, model=MODEL_NAME, temperature=0.2)


# ===============================
# Processed Documents UI & Modal
# ===============================

def register_processed_document(
    filename: str,
    template_name: str,
    schema: Dict[str, Any],
    raw_text: str,
    json_result: Any,
) -> None:
    """Store processed document metadata in session_state."""
    doc_id = str(uuid.uuid4())
    df = pd.DataFrame(json_result) if isinstance(json_result, list) else pd.DataFrame()

    st.session_state.processed_docs.append(
        {
            "id": doc_id,
            "filename": filename,
            "template_name": template_name,
            "schema": schema,
            "raw_text": raw_text,
            "json_result": json_result,
            "dataframe": df,
        }
    )


def render_processed_documents_list() -> None:
    """Render list of processed documents with clickable items."""
    st.subheader("ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹")

    if not st.session_state.processed_docs:
        st.info("ÐŸÐ¾ÐºÐ° Ð½ÐµÑ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð².")
        return

    for doc in st.session_state.processed_docs:
        cols = st.columns([4, 3, 2])
        label = f"{doc['filename']} (ÑˆÐ°Ð±Ð»Ð¾Ð½: {doc['template_name']})"
        if cols[0].button(label, key=f"doc_button_{doc['id']}"):
            st.session_state.selected_doc_id = doc["id"]
            st.session_state.show_result_modal = True

        cols[1].markdown(f"**Ð¡Ñ‚Ñ€Ð¾Ðº:** {len(doc['dataframe'])}")
        cols[2].markdown(f"**ID:** `{doc['id'][:8]}...`")


@st.dialog("Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ")
def show_result_dialog() -> None:
    """Modal dialog with table and download buttons for selected document."""
    doc_id = st.session_state.get("selected_doc_id")
    if not doc_id:
        st.write("Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð½Ðµ Ð²Ñ‹Ð±Ñ€Ð°Ð½.")
        if st.button("Ð—Ð°ÐºÑ€Ñ‹Ñ‚ÑŒ"):
            st.session_state.show_result_modal = False
            st.experimental_rerun()
        return

    doc = next((d for d in st.session_state.processed_docs if d["id"] == doc_id), None)
    if not doc:
        st.write("Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½.")
        if st.button("Ð—Ð°ÐºÑ€Ñ‹Ñ‚ÑŒ"):
            st.session_state.show_result_modal = False
            st.experimental_rerun()
        return

    st.markdown(f"**Ð¤Ð°Ð¹Ð»:** {doc['filename']}")
    st.markdown(f"**Ð¨Ð°Ð±Ð»Ð¾Ð½:** {doc['template_name']}")

    st.markdown("**Ð¢Ð°Ð±Ð»Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð²Ð¸Ð´ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²:**")
    st.dataframe(doc["dataframe"], use_container_width=True)

    json_str = json.dumps(doc["json_result"], ensure_ascii=False, indent=2)
    csv_str = doc["dataframe"].to_csv(index=False)

    st.download_button(
        "â¬‡ï¸ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ JSON",
        data=json_str.encode("utf-8"),
        file_name=f"{doc['filename']}.json",
        mime="application/json",
        key=f"download_json_{doc_id}",
    )

    st.download_button(
        "â¬‡ï¸ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ CSV",
        data=csv_str.encode("utf-8"),
        file_name=f"{doc['filename']}.csv",
        mime="text/csv",
        key=f"download_csv_{doc_id}",
    )

    st.markdown("---")
    if st.button("Ð—Ð°ÐºÑ€Ñ‹Ñ‚ÑŒ"):
        st.session_state.show_result_modal = False
        st.experimental_rerun()


# ===============================
# Document Upload & Processing UI
# ===============================

def render_document_processing() -> None:
    st.subheader("Document Upload & Processing")

    uploaded_file = st.file_uploader(
        "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚",
        type=["txt", "pdf", "docx", "csv", "xlsx"],
    )

    if not st.session_state.templates:
        st.warning("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° ÑÐ¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚Ðµ Ñ…Ð¾Ñ‚Ñ Ð±Ñ‹ Ð¾Ð´Ð¸Ð½ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð² ÑÐµÐºÑ†Ð¸Ð¸ Structured Output Builder.")
        selected_template_name = None
    else:
        selected_template_name = st.selectbox(
            "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ",
            options=list(st.session_state.templates.keys()),
        )

    if st.button("ðŸš€ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚"):
        if not uploaded_file:
            st.error("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ñ„Ð°Ð¹Ð».")
            return
        if not selected_template_name:
            st.error("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑˆÐ°Ð±Ð»Ð¾Ð½.")
            return

        with st.spinner("Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐºÑÑ‚Ð° Ð¸Ð· Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°..."):
            try:
                text = extract_text_from_file(uploaded_file)
            except Exception as e:
                st.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ‡Ñ‚ÐµÐ½Ð¸Ð¸ Ñ„Ð°Ð¹Ð»Ð°: {e}")
                return

        template_obj = st.session_state.templates[selected_template_name]

        # Backward compatibility: ÑÑ‚Ð°Ñ€Ñ‹Ðµ ÑˆÐ°Ð±Ð»Ð¾Ð½Ñ‹ Ð¼Ð¾Ð³Ð»Ð¸ Ð±Ñ‹Ñ‚ÑŒ "Ñ‡Ð¸ÑÑ‚Ð¾Ð¹" ÑÑ…ÐµÐ¼Ð¾Ð¹ Ð±ÐµÐ· Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾Ð»ÐµÐ¹.
        if isinstance(template_obj, dict) and "schema" in template_obj:
            schema = template_obj["schema"]
            fields_meta = template_obj.get("fields") or []
        else:
            schema = template_obj
            fields_meta = []

        with st.spinner("Ð’Ñ‹Ð·Ð¾Ð² Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ollama Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹..."):
            json_result, raw_output, validation_error = extract_structured_data(
                schema,
                text,
                fields_meta=fields_meta,
                max_retries=1,
            )

        if json_result is None:
            st.error("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¹ JSON Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸.")
            if validation_error:
                st.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸: {validation_error}")
            with st.expander("ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÑ‹Ñ€Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸"):
                st.code(raw_output)
            return

        st.success("Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ñ‹.")
        register_processed_document(
            filename=uploaded_file.name,
            template_name=selected_template_name,
            schema=schema,
            raw_text=text,
            json_result=json_result,
        )


# ===============================
# Document Analysis & Summarization UI
# ===============================

def render_document_analysis() -> None:
    st.subheader("Document Analysis & Summarization")

    uploaded_file = st.file_uploader(
        "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°",
        type=["txt", "pdf", "docx", "csv", "xlsx"],
        key="analysis_file_uploader",
    )

    level = st.selectbox(
        "Ð”ÐµÑ‚Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ€ÐµÐ·ÑŽÐ¼Ðµ",
        options=[
            ("short", "ÐšÑ€Ð°Ñ‚ÐºÐ¾ (3â€“5 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹)"),
            ("balanced", "Ð¡Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ (5â€“10 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹)"),
            ("detailed", "ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½Ð¾"),
        ],
        format_func=lambda x: x[1],
    )[0]

    focus = st.text_area(
        "Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ñ„Ð¾ÐºÑƒÑ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)",
        help="ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Â«Ð¡Ñ„Ð¾ÐºÑƒÑÐ¸Ñ€ÑƒÐ¹ÑÑ Ð½Ð° ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ñ€Ð¸ÑÐºÐ°Ñ…Â», Â«Ð¡Ð´ÐµÐ»Ð°Ð¹ Ð°ÐºÑ†ÐµÐ½Ñ‚ Ð½Ð° Ñ†Ð¸Ñ„Ñ€Ð°Ñ… Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ñ…Â», "
             "Â«Ð’Ñ‹Ð´ÐµÐ»Ð¸ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð° Ð¸ ÑÑ€Ð¾ÐºÐ¸Â»",
    )

    if st.button("ðŸ”Ž ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚"):
        if not uploaded_file:
            st.error("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ñ„Ð°Ð¹Ð».")
            return

        with st.spinner("Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐºÑÑ‚Ð° Ð¸Ð· Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°..."):
            try:
                text = extract_text_from_file(uploaded_file)
            except Exception as e:
                st.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ‡Ñ‚ÐµÐ½Ð¸Ð¸ Ñ„Ð°Ð¹Ð»Ð°: {e}")
                return

        if not text.strip():
            st.warning("Ð’ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ðµ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°.")
            return

        with st.spinner("Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ Ð°Ð½Ð°Ð»Ð¸Ð· Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð° Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ LLM..."):
            summary = summarize_document(text, focus=focus, level=level)

        st.success("ÐÐ½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½.")
        st.markdown("**Ð ÐµÐ·ÑŽÐ¼Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°:**")
        st.markdown(summary)

        with st.expander("ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°"):
            st.text(text)


# ===============================
# Main App
# ===============================

def main() -> None:
    st.set_page_config(
        page_title="AI Structured Extraction Platform",
        layout="wide",
    )

    init_session_state()

    st.title("AI Structured Extraction Platform")
    st.caption("Document â†’ Text â†’ LLM â†’ JSON Array â†’ Table â†’ Modal")

    builder_tab, processing_tab, analysis_tab = st.tabs(
        [
            "1. Structured Output Builder",
            "2. Document Upload & Processing",
            "3. Document Analysis & Summarization",
        ]
    )

    with builder_tab:
        render_schema_builder()

    with processing_tab:
        col_left, col_right = st.columns([2, 3])
        with col_left:
            render_document_processing()
        with col_right:
            render_processed_documents_list()

    with analysis_tab:
        render_document_analysis()

    # Show result modal if needed
    if st.session_state.get("show_result_modal", False):
        show_result_dialog()


if __name__ == "__main__":
    main()